{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import urllib.request as urllib2\n",
    "import time\n",
    "from selenium.webdriver.support.select import Select\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ball by ball data (Initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Extracting_1114856_Inns1_Page1 content\n",
      "Extracting_1114856_Inns1_Page2 content\n",
      "Extracting_1114856_Inns1_Page3 content\n",
      "Extracting_1114856_Inns1_Page4 content\n",
      "Extracting_1114856_Inns1_Page5 content\n",
      "Extracting_1114856_Inns2_Page1 content\n",
      "Extracting_1114856_Inns2_Page2 content\n",
      "Extracting_1114856_Inns2_Page3 content\n",
      "Extracting_1114856_Inns2_Page4 content\n",
      "Extracting_1114856_Inns2_Page5 content\n",
      "Scraping process over\n"
     ]
    }
   ],
   "source": [
    "#Declaring all lists and dataframes\n",
    "match_list=[]\n",
    "inns_list=[]\n",
    "ball_list=[]\n",
    "over_list=[]\n",
    "runs_list=[]\n",
    "comm_short_list=[]\n",
    "comm_long_list=[]\n",
    "bat_team_list=[]\n",
    "bowl_team_list=[]\n",
    "striker_bat_id_list=[]\n",
    "nonstriker_bat_id_list=[]\n",
    "striker_bat_name_list=[]\n",
    "nonstriker_bat_name_list=[]\n",
    "main_bow_id_list=[]\n",
    "other_bow_id_list=[]\n",
    "main_bow_name_list=[]\n",
    "other_bow_name_list=[]\n",
    "isBoundary_list=[]\n",
    "wide_runs_list=[]\n",
    "#legbye_runs_list=[]\n",
    "bye_legbye_runs_list=[]\n",
    "nb_runs_list=[]\n",
    "batsman_runs_list=[]\n",
    "extras_runs_list=[]\n",
    "is_wkt_list=[]\n",
    "is_bow_wkt_list=[]\n",
    "wkt_data_list=[]\n",
    "curr_bat_list=[]\n",
    "curr_bow_list=[]\n",
    "curr_inn_list=[]\n",
    "match_over_list=[]\n",
    "\n",
    "for mid in matchid_list:\n",
    "    url_match='https://www.espncricinfo.com/series/8048/commentary/{}/trinbago-knight-riders-vs-st-kitts-and-nevis-patriots-1st-match-caribbean-premier-league-2019'.format(mid)\n",
    "    driver = webdriver.Chrome(\"D:/Downloads/chromedriver_win32/chromedriver.exe\")\n",
    "    driver.get(url_match)\n",
    "    content = driver.page_source\n",
    "    soup = BeautifulSoup(content)\n",
    "    team_list=[]\n",
    "    for teams in soup.findAll('div',attrs={'class':'teams'}):\n",
    "        for team in teams.findAll('div',attrs={'class':'team'}):\n",
    "            team_list.append(team.find('span').attrs['title'])\n",
    "    driver.quit()    \n",
    "    print(' ')\n",
    "    \n",
    "    for inns in np.arange(1,3):\n",
    "        url='https://hsapi.espncricinfo.com/v1/pages/match/comments?lang=en&leagueId=8048&eventId={match}&liveTest=false&period={inns}&page=1'.format(match=mid,inns=inns)\n",
    "        driver = webdriver.Chrome(\"D:/Downloads/chromedriver_win32/chromedriver.exe\")\n",
    "        driver.get(url)\n",
    "        content = driver.page_source\n",
    "        soup = BeautifulSoup(content)\n",
    "        total_pages=json.loads(soup.text)['pagination']['pageCount']\n",
    "        driver.quit()\n",
    "        \n",
    "        for page in np.arange(total_pages):\n",
    "            #Code to retrieve json data for the page\n",
    "            url_page='https://hsapi.espncricinfo.com/v1/pages/match/comments?lang=en&leagueId=8048&eventId={match}&liveTest=false&period={inns}&page={page}'.format(match=mid,inns=inns,page=page+1)\n",
    "            driver = webdriver.Chrome(\"D:/Downloads/chromedriver_win32/chromedriver.exe\")\n",
    "            driver.get(url_page)\n",
    "            content = driver.page_source\n",
    "            soup = BeautifulSoup(content)\n",
    "            soup_data=json.loads(soup.text)\n",
    "            print('Extracting_{match}_Inns{inns}_Page{page} content'.format(match=mid,inns=inns,page=page+1))\n",
    "            #with open('Downloaded webpages\\CPL_2019_{match}_Inns{inns}_Page{page}.html'.format(match=mid,inns=inns,page=page+1), 'w') as f:\n",
    "            #    f.write(content)\n",
    "            #driver.quit()\n",
    "            #print('Downloaded CPL_2019_{match}_Inns{inns}_Page{page} webpage'.format(match=mid,inns=inns,page=page+1))\n",
    "            \n",
    "            #Code to load page json data into dataframe\n",
    "            #with open('Downloaded webpages\\CPL_2019_{match}_Inns{inns}_Page{page}.html'.format(match=mid,inns=inns,page=page+1)) as fp:\n",
    "            #    soup_data = json.loads(BeautifulSoup(fp, \"html5lib\").text)\n",
    "            for ball_ind in np.arange(len(soup_data['comments'])):\n",
    "                ball_data=soup_data['comments'][ball_ind]\n",
    "                match_list.append(mid)\n",
    "                inns_list.append(inns)\n",
    "                if inns==1:\n",
    "                    bat_team_list.append(team_list[0])\n",
    "                    bowl_team_list.append(team_list[1])\n",
    "                else:\n",
    "                    bat_team_list.append(team_list[1])\n",
    "                    bowl_team_list.append(team_list[0])        \n",
    "                ball_list.append(ball_data['ball'])\n",
    "                over_list.append(ball_data['over']+1)\n",
    "                runs_list.append(ball_data['runs'])\n",
    "                comm_short_list.append(ball_data['shortText'])\n",
    "                comm_long_list.append(ball_data['text'])\n",
    "                striker_bat_id_list.append(ball_data['currentBatsmen'][0]['id'])\n",
    "                nonstriker_bat_id_list.append(ball_data['currentBatsmen'][1]['id'])\n",
    "                striker_bat_name_list.append(ball_data['currentBatsmen'][0]['name'])\n",
    "                nonstriker_bat_name_list.append(ball_data['currentBatsmen'][1]['name'])\n",
    "                main_bow_id_list.append(ball_data['currentBowlers'][0]['id'])\n",
    "                main_bow_name_list.append(ball_data['currentBowlers'][0]['name'])\n",
    "                extras_runs_list.append(0)\n",
    "    \n",
    "                if 'id' in ball_data['currentBowlers'][1]:\n",
    "                    other_bow_id_list.append(ball_data['currentBowlers'][1]['id'])\n",
    "                else:\n",
    "                    other_bow_id_list.append(np.nan)\n",
    "\n",
    "                if 'name' in ball_data['currentBowlers'][1]:\n",
    "                    other_bow_name_list.append(ball_data['currentBowlers'][1]['name'])                    \n",
    "                else:\n",
    "                    other_bow_name_list.append(np.nan)\n",
    "\n",
    "                if str(ball_data['isBoundary'])=='True':\n",
    "                    isBoundary_list.append(1)\n",
    "                else:\n",
    "                    isBoundary_list.append(0)\n",
    "\n",
    "                if str(ball_data['isWide'])=='True':\n",
    "                    wide_runs_list.append(ball_data['runs'])\n",
    "                    nb_runs_list.append(0)\n",
    "                    bye_legbye_runs_list.append(0)\n",
    "                    batsman_runs_list.append(0)\n",
    "                elif ((str(ball_data['isNoball'])=='True')):\n",
    "                    wide_runs_list.append(0)\n",
    "                    bye_legbye_runs_list.append(0)\n",
    "                    if (re.search('[(]no ball[)]', ball_data['shortText'])):\n",
    "                        nb_runs_list.append(1)\n",
    "                        batsman_runs_list.append(ball_data['runs'] - 1)\n",
    "                    else:    \n",
    "                        nb_runs_list.append(ball_data['runs'])\n",
    "                        batsman_runs_list.append(0)                        \n",
    "                elif ('bye' in ball_data['shortText'].split(', ')[1]):\n",
    "                    bye_legbye_runs_list.append(ball_data['runs'])\n",
    "                    wide_runs_list.append(0)\n",
    "                    nb_runs_list.append(0)                    \n",
    "                    batsman_runs_list.append(0)\n",
    "                else:\n",
    "                    wide_runs_list.append(0)\n",
    "                    nb_runs_list.append(0)\n",
    "                    batsman_runs_list.append(ball_data['runs']) \n",
    "                    bye_legbye_runs_list.append(0)\n",
    "                    \n",
    "                if 'matchWicket' in ball_data:\n",
    "                    is_wkt_list.append(1)\n",
    "                    wkt_data_list.append(ball_data['matchWicket'])\n",
    "                    if re.search('(run out|obstructing the field)',ball_data['matchWicket']['text']):\n",
    "                        is_bow_wkt_list.append(0)\n",
    "                    else:\n",
    "                        is_bow_wkt_list.append(1)\n",
    "                else:\n",
    "                    is_wkt_list.append(0)\n",
    "                    wkt_data_list.append(0)\n",
    "                    is_bow_wkt_list.append(0)\n",
    "                    \n",
    "                if 'matchOver' in ball_data:\n",
    "                    match_over_list.append(ball_data['matchOver'])\n",
    "                else:\n",
    "                    match_over_list.append(0)\n",
    "                    \n",
    "                curr_bat_list.append(ball_data['currentBatsmen'])\n",
    "                curr_bow_list.append(ball_data['currentBowlers'])\n",
    "                curr_inn_list.append(ball_data['currentInning'])\n",
    "            driver.quit()        \n",
    "    \n",
    "ball_by_ball_df=pd.DataFrame(list(zip(match_list,inns_list,over_list,ball_list,bat_team_list,bowl_team_list,striker_bat_id_list,striker_bat_name_list,nonstriker_bat_id_list,nonstriker_bat_name_list,main_bow_id_list,main_bow_name_list,other_bow_id_list,other_bow_name_list,isBoundary_list,wide_runs_list,nb_runs_list,bye_legbye_runs_list,extras_runs_list,batsman_runs_list,runs_list,is_wkt_list,is_bow_wkt_list,wkt_data_list,match_over_list,curr_bat_list,curr_bow_list,curr_inn_list,comm_short_list,comm_long_list)),\n",
    "                             columns=['Match id','Inns','Over','Ball','Batting team','Bowling team','Strike batsman id','Strike batsman name','Non-strike batsman id','Non-strike batsman name','Main bowler id','Main bowler name','Other end bowler id','Other end bowler name','Is Boundary','Wide runs','No ball runs','Bye and leg bye runs','Extras runs','Batsman runs','Total Runs','Is wicket','Is Bowler wicket','Wicket data','Over data','Batsmen data','Bowlers data','Innings data until then','Short comm','Long Comm'])\n",
    "ball_by_ball_df['Extras runs']=ball_by_ball_df['Wide runs']+ball_by_ball_df['No ball runs']+ball_by_ball_df['Bye and leg bye runs']\n",
    "ball_by_ball_df=ball_by_ball_df.sort_values(['Match id','Inns','Over','Ball'])\n",
    "ball_by_ball_df.to_csv('Output folder\\BBB_data.csv',index=False) \n",
    "\n",
    "print('Scraping process over')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matches data (Initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Match 1114856 data\n",
      " \n",
      "Scraping process over\n"
     ]
    }
   ],
   "source": [
    "match_list=[]\n",
    "leagueName=[]\n",
    "leagueAbbreviation=[]\n",
    "matchYear=[]\n",
    "season=[]\n",
    "matchNum=[]\n",
    "date=[]\n",
    "venue=[]\n",
    "city=[]\n",
    "country=[]\n",
    "homeTeamName=[]\n",
    "homeTeamAbbr=[]\n",
    "homeTeamCap=[]\n",
    "homeTeamScore=[]\n",
    "awayTeamName=[]\n",
    "awayTeamAbbr=[]\n",
    "awayTeamCap=[]\n",
    "awayTeamScore=[]\n",
    "winner=[]\n",
    "resultType=[]\n",
    "tossWinner=[]\n",
    "tossDecision=[]\n",
    "bestPlayer=[]\n",
    "bestPlayerTeam=[]\n",
    "umpire1=[]\n",
    "umpire2=[]\n",
    "tvUmpire=[]\n",
    "reserveUmpire=[]\n",
    "matchReferee=[]\n",
    "inns1Scorecard=[]\n",
    "inns2Scorecard=[]\n",
    "teams=[]\n",
    "\n",
    "for mid in matchid_list:\n",
    "    url_page='https://hsapi.espncricinfo.com/v1/pages/match/scoreboard?lang=en&leagueId=8048&eventId={match}&liveTest=false&qaTest=false'.format(match=mid)\n",
    "    driver = webdriver.Chrome(\"D:/Downloads/chromedriver_win32/chromedriver.exe\")\n",
    "    driver.get(url_page)\n",
    "    content = driver.page_source\n",
    "    soup = BeautifulSoup(content)\n",
    "    soup_data=json.loads(soup.text)\n",
    "    \n",
    "    print('Extracting Match {} data'.format(mid))\n",
    "    \n",
    "    match_list.append(mid)\n",
    "    leagueName.append(soup_data['meta']['leagueName'])\n",
    "    leagueAbbreviation.append(soup_data['meta']['leagueAbbreviation'])\n",
    "    season.append(soup_data['header']['matchEvent']['season'])\n",
    "    matchYear.append(soup_data['meta']['matchYear'])\n",
    "    matchNum.append(soup_data['meta']['matchNum'])\n",
    "    date.append(soup_data['content']['about']['matchdays'])\n",
    "    venue.append(soup_data['header']['matchEvent']['venue']['name'])\n",
    "    city.append(soup_data['header']['matchEvent']['venue']['city'])\n",
    "    country.append(soup_data['header']['matchEvent']['venue']['country'])\n",
    "    homeTeamName.append(soup_data['meta']['homeTeamName'])\n",
    "    homeTeamAbbr.append(soup_data['meta']['homeTeamAbbr'])\n",
    "    awayTeamName.append(soup_data['meta']['awayTeamName'])\n",
    "    awayTeamAbbr.append(soup_data['meta']['awayTeamAbbr'])\n",
    "    homeTeamCap.append(soup_data['header']['matchEvent']['competitors'][0]['captain']['displayName'])\n",
    "    awayTeamCap.append(soup_data['header']['matchEvent']['competitors'][1]['captain']['displayName'])\n",
    "    homeTeamScore.append(soup_data['header']['matchEvent']['competitors'][0]['score'])\n",
    "    awayTeamScore.append(soup_data['header']['matchEvent']['competitors'][1]['score'])\n",
    "    \n",
    "    if str(soup_data['header']['matchEvent']['competitors'][0]['isWinner'])=='True':\n",
    "        winner.append(soup_data['header']['matchEvent']['competitors'][0]['name'])\n",
    "    elif str(soup_data['header']['matchEvent']['competitors'][1]['isWinner'])=='True':\n",
    "        winner.append(soup_data['header']['matchEvent']['competitors'][1]['name'])\n",
    "    else:\n",
    "        winner.append('Tie')\n",
    "        \n",
    "    resultType.append(soup_data['header']['matchEvent']['statusText'])\n",
    "    tossWinner.append(soup_data['content']['about']['toss'].split(' , ')[0])\n",
    "    tossDecision.append(soup_data['content']['about']['toss'].split(' , ')[1])\n",
    "    bestPlayer.append(soup_data['header']['bestPlayer']['name'])\n",
    "    bestPlayerTeam.append(soup_data['header']['bestPlayer']['teamName'])\n",
    "    matchReferee.append(soup_data['content']['about']['referee'][0]['text'])\n",
    "    umpire1.append(soup_data['content']['about']['umpire'][0]['text'])\n",
    "    umpire2.append(soup_data['content']['about']['umpire'][1]['text'])\n",
    "    reserveUmpire.append(soup_data['content']['about']['reserve umpire'][0]['text'])\n",
    "    tvUmpire.append(soup_data['content']['about']['tv umpire'][0]['text'])\n",
    "    inns1Scorecard.append(soup_data['content']['innings'][0])\n",
    "    inns2Scorecard.append(soup_data['content']['innings'][1])\n",
    "    teams.append(soup_data['content']['teams'][0])\n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "print(' ')    \n",
    "print('Scraping process over')\n",
    "\n",
    "matches_df=pd.DataFrame(list(zip(match_list,leagueName,leagueAbbreviation,season,matchYear,matchNum,date,venue,city,country,\n",
    "                                 homeTeamName,homeTeamAbbr,homeTeamCap,homeTeamScore,awayTeamName,awayTeamAbbr,awayTeamCap,\n",
    "                                 awayTeamScore,winner,resultType,tossWinner,tossDecision,bestPlayer,bestPlayerTeam,umpire1,\n",
    "                                 umpire2,tvUmpire,reserveUmpire,matchReferee,inns1Scorecard,inns2Scorecard,teams)),\n",
    "                        columns=['Overall Match Id','League Name','League Abbr','Season','Match Year','Match no in Season',\n",
    "                                 'Date','Venue','City','Country','Home team name','Home team Abbr','Home team cap',\n",
    "                                 'Home team score','Away team name','Away team Abbr','Away team cap','Away team score',\n",
    "                                 'Winner','Result type','Toss Winner','Toss decision','MoM','MoM team','Umpire 1','Umpire 2',\n",
    "                                 'TV Umpire','Reserve Umpire','Match Referee','Inns 1 Scorecard','Inns 2 Scorecard','Team players'])  \n",
    "matches_df.to_csv('Output folder\\Matches_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Players data (initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting player 787073 data\n",
      "Extracting player 4498 data\n",
      "Extracting player 826901 data\n",
      "Extracting player 505110 data\n",
      "Extracting player 297628 data\n",
      "Extracting player 7069 data\n",
      "Extracting player 4508 data\n",
      "Extracting player 270493 data\n",
      "Extracting player 825211 data\n",
      "Extracting player 901157 data\n",
      "Extracting player 6973 data\n",
      "Extracting player 298438 data\n",
      "Extracting player 5961 data\n",
      "Extracting player 398666 data\n",
      "Extracting player 319439 data\n",
      "Extracting player 333780 data\n",
      "Extracting player 240609 data\n",
      "Extracting player 308967 data\n",
      "Extracting player 571761 data\n",
      "Extracting player 8180 data\n",
      "Extracting player 44149 data\n",
      "Extracting player 7547 data\n",
      "Scraping process over\n"
     ]
    }
   ],
   "source": [
    "players_id=[]\n",
    "players_df=pd.DataFrame(columns=['Player Id','Full Name','Playing role','Batting style','Bowling style'])\n",
    "\n",
    "bbb_data=pd.read_csv('Output folder\\BBB_data.csv')\n",
    "#bbb_data.dropna(subset=['Other end bowler id'], inplace=True)\n",
    "#bbb_data['Other end bowler id']=bbb_data['Other end bowler id'].astype(int)\n",
    "\n",
    "players_id.append(list(set(bbb_data['Strike batsman id'])))\n",
    "players_id.append(list(set(bbb_data['Non-strike batsman id'])))\n",
    "players_id.append(list(set(bbb_data['Main bowler id'])))\n",
    "players_id.append(list(set(bbb_data['Other end bowler id'])))\n",
    "\n",
    "players_list = [item for sublist in players_id for item in sublist]\n",
    "players_list = [x for x in players_list if str(x) != 'nan']\n",
    "players_list=list(set(players_list))\n",
    "\n",
    "players_df['Player Id']=players_list\n",
    "players_df.set_index('Player Id',inplace=True)\n",
    "\n",
    "for pid in players_df.index.values.tolist():\n",
    "    url_page='https://www.espncricinfo.com/india/content/player/{}.html'.format(pid)\n",
    "    driver = webdriver.Chrome(\"D:/Downloads/chromedriver_win32/chromedriver.exe\")\n",
    "    driver.get(url_page)\n",
    "    content = driver.page_source\n",
    "    soup = BeautifulSoup(content)\n",
    "    \n",
    "    print('Extracting player {} data'.format(pid))\n",
    "    \n",
    "    for tag in soup.findAll('p',attrs={'class':'ciPlayerinformationtxt'}):\n",
    "        for subtag in tag.findAll('b'):\n",
    "            if subtag.text == 'Full name':\n",
    "                players_df.loc[pid]['Full Name']=tag.findAll('span')[0].text\n",
    "            if subtag.text == 'Playing role':\n",
    "                players_df.loc[pid]['Playing role']=tag.findAll('span')[0].text\n",
    "            if subtag.text == 'Batting style':\n",
    "                players_df.loc[pid]['Batting style']=tag.findAll('span')[0].text\n",
    "            if subtag.text == 'Bowling style':\n",
    "                players_df.loc[pid]['Bowling style']=tag.findAll('span')[0].text\n",
    "    driver.quit()        \n",
    "\n",
    "print('Scraping process over')    \n",
    "players_df.to_csv('Output folder\\Players_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get matchids list from Cricsheet list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1195618',\n",
       " '1195619',\n",
       " '1195620',\n",
       " '1195621',\n",
       " '1195622',\n",
       " '1195623',\n",
       " '1195624',\n",
       " '1195625',\n",
       " '1195626',\n",
       " '1195627',\n",
       " '1195628',\n",
       " '1195629',\n",
       " '1195630',\n",
       " '1195631',\n",
       " '1195632',\n",
       " '1195633']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchid_list = [f.split('.')[0] for f in os.listdir(r'Input matches')]\n",
    "matchid_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input matchids manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the matchids for the matches for which ball by ball is required. To stop, please press Enter\n",
      "1226866\n",
      "1226863\n",
      "1226867\n",
      "1226830\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1226866', '1226863', '1226867', '1226830']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchid_list=[]\n",
    "print('Enter the matchids for the matches for which ball by ball is required. To stop, please press Enter')\n",
    "while True:\n",
    "    text=input()\n",
    "    if text:\n",
    "        matchid_list.append(text)\n",
    "        continue\n",
    "    else:    \n",
    "        break\n",
    "matchid_list        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matches data (Incremental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Match 1226866 data\n",
      "Extracting Match 1226863 data\n",
      "Extracting Match 1226867 data\n",
      "Extracting Match 1226830 data\n",
      " \n",
      "Scraping process over\n"
     ]
    }
   ],
   "source": [
    "match_list=[]\n",
    "leagueName=[]\n",
    "leagueAbbreviation=[]\n",
    "matchYear=[]\n",
    "season=[]\n",
    "matchNum=[]\n",
    "date=[]\n",
    "venue=[]\n",
    "city=[]\n",
    "country=[]\n",
    "homeTeamName=[]\n",
    "homeTeamAbbr=[]\n",
    "homeTeamCap=[]\n",
    "homeTeamScore=[]\n",
    "awayTeamName=[]\n",
    "awayTeamAbbr=[]\n",
    "awayTeamCap=[]\n",
    "awayTeamScore=[]\n",
    "winner=[]\n",
    "resultType=[]\n",
    "tossWinner=[]\n",
    "tossDecision=[]\n",
    "bestPlayer=[]\n",
    "bestPlayerTeam=[]\n",
    "umpire1=[]\n",
    "umpire2=[]\n",
    "tvUmpire=[]\n",
    "reserveUmpire=[]\n",
    "matchReferee=[]\n",
    "inns1Scorecard=[]\n",
    "inns2Scorecard=[]\n",
    "teams=[]\n",
    "matches_data_old=pd.read_csv('Output folder\\Matches_data.csv')\n",
    "\n",
    "for mid in matchid_list:\n",
    "    url_page='https://hsapi.espncricinfo.com/v1/pages/match/scoreboard?lang=en&leagueId=8048&eventId={match}&liveTest=false&qaTest=false'.format(match=mid)\n",
    "    driver = webdriver.Chrome(\"D:/Downloads/chromedriver_win32/chromedriver.exe\")\n",
    "    driver.get(url_page)\n",
    "    content = driver.page_source\n",
    "    soup = BeautifulSoup(content)\n",
    "    soup_data=json.loads(soup.text)\n",
    "    \n",
    "    print('Extracting Match {} data'.format(mid))\n",
    "    \n",
    "    match_list.append(mid)\n",
    "    leagueName.append(soup_data['meta']['leagueName'])\n",
    "    leagueAbbreviation.append(soup_data['meta']['leagueAbbreviation'])\n",
    "    season.append(soup_data['header']['matchEvent']['season'])\n",
    "    matchYear.append(soup_data['meta']['matchYear'])\n",
    "    matchNum.append(soup_data['meta']['matchNum'])\n",
    "    date.append(soup_data['content']['about']['matchdays'])\n",
    "    venue.append(soup_data['header']['matchEvent']['venue']['name'])\n",
    "    city.append(soup_data['header']['matchEvent']['venue']['city'])\n",
    "    country.append(soup_data['header']['matchEvent']['venue']['country'])\n",
    "    homeTeamName.append(soup_data['meta']['homeTeamName'])\n",
    "    homeTeamAbbr.append(soup_data['meta']['homeTeamAbbr'])\n",
    "    awayTeamName.append(soup_data['meta']['awayTeamName'])\n",
    "    awayTeamAbbr.append(soup_data['meta']['awayTeamAbbr'])\n",
    "    homeTeamCap.append(soup_data['header']['matchEvent']['competitors'][0]['captain']['displayName'])\n",
    "    awayTeamCap.append(soup_data['header']['matchEvent']['competitors'][1]['captain']['displayName'])\n",
    "    homeTeamScore.append(soup_data['header']['matchEvent']['competitors'][0]['score'])\n",
    "    awayTeamScore.append(soup_data['header']['matchEvent']['competitors'][1]['score'])\n",
    "    \n",
    "    if str(soup_data['header']['matchEvent']['competitors'][0]['isWinner'])=='True':\n",
    "        winner.append(soup_data['header']['matchEvent']['competitors'][0]['name'])\n",
    "    elif str(soup_data['header']['matchEvent']['competitors'][1]['isWinner'])=='True':\n",
    "        winner.append(soup_data['header']['matchEvent']['competitors'][1]['name'])\n",
    "    else:\n",
    "        winner.append('Tie/NR')\n",
    "        \n",
    "    resultType.append(soup_data['header']['matchEvent']['statusText'])\n",
    "    tossWinner.append(soup_data['content']['about']['toss'].split(' , ')[0])\n",
    "    tossDecision.append(soup_data['content']['about']['toss'].split(' , ')[1])\n",
    "    if 'bestPlayer' in soup_data['header']:\n",
    "        bestPlayer.append(soup_data['header']['bestPlayer']['name'])\n",
    "    else:\n",
    "        bestPlayer.append(np.nan)\n",
    "    if 'bestPlayer' in soup_data['header']:\n",
    "        bestPlayerTeam.append(soup_data['header']['bestPlayer']['teamName'])\n",
    "    else:\n",
    "        bestPlayerTeam.append(np.nan)\n",
    "    matchReferee.append(soup_data['content']['about']['referee'][0]['text'])\n",
    "    umpire1.append(soup_data['content']['about']['umpire'][0]['text'])\n",
    "    umpire2.append(soup_data['content']['about']['umpire'][1]['text'])\n",
    "    \n",
    "    if 'reserve umpire' in soup_data['content']['about']:\n",
    "        reserveUmpire.append(soup_data['content']['about']['reserve umpire'][0]['text'])\n",
    "    else:\n",
    "        reserveUmpire.append(np.nan)\n",
    "    \n",
    "    if 'tv umpire' in soup_data['content']['about']: \n",
    "        tvUmpire.append(soup_data['content']['about']['tv umpire'][0]['text'])\n",
    "    else:\n",
    "        tvUmpire.append(np.nan)\n",
    "    \n",
    "    try:\n",
    "        inns1Scorecard.append(soup_data['content']['innings'][0])\n",
    "    except:\n",
    "        inns1Scorecard.append(np.nan)\n",
    "    \n",
    "    try:    \n",
    "        inns2Scorecard.append(soup_data['content']['innings'][1])\n",
    "    except:\n",
    "        inns2Scorecard.append(np.nan)\n",
    "        \n",
    "    teams.append(soup_data['content']['teams'][0])\n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "print(' ')    \n",
    "print('Scraping process over')\n",
    "\n",
    "matches_df=pd.DataFrame(list(zip(match_list,leagueName,leagueAbbreviation,season,matchYear,matchNum,date,venue,city,country,\n",
    "                                 homeTeamName,homeTeamAbbr,homeTeamCap,homeTeamScore,awayTeamName,awayTeamAbbr,awayTeamCap,\n",
    "                                 awayTeamScore,winner,resultType,tossWinner,tossDecision,bestPlayer,bestPlayerTeam,umpire1,\n",
    "                                 umpire2,tvUmpire,reserveUmpire,matchReferee,inns1Scorecard,inns2Scorecard,teams)),\n",
    "                        columns=['Overall Match Id','League Name','League Abbr','Season','Match Year','Match no in Season',\n",
    "                                 'Date','Venue','City','Country','Home team name','Home team Abbr','Home team cap',\n",
    "                                 'Home team score','Away team name','Away team Abbr','Away team cap','Away team score',\n",
    "                                 'Winner','Result type','Toss Winner','Toss decision','MoM','MoM team','Umpire 1','Umpire 2',\n",
    "                                 'TV Umpire','Reserve Umpire','Match Referee','Inns 1 Scorecard','Inns 2 Scorecard','Team players'])  \n",
    "matches_df=matches_data_old.append(matches_df,ignore_index=True)\n",
    "matches_df['Overall Match Id']=matches_df['Overall Match Id'].astype(str)\n",
    "matches_df=matches_df.sort_values('Overall Match Id')\n",
    "matches_df.to_csv('Output folder\\Matches_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ball by ball data (Incremental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Downloads\\Anaconda\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (8,30) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting_1226866_Inns1_Page1 content\n",
      "Extracting_1226866_Inns1_Page2 content\n",
      "Extracting_1226866_Inns1_Page3 content\n",
      "Extracting_1226866_Inns1_Page4 content\n",
      "Extracting_1226866_Inns1_Page5 content\n",
      "Extracting_1226866_Inns2_Page1 content\n",
      "Extracting_1226866_Inns2_Page2 content\n",
      "Extracting_1226866_Inns2_Page3 content\n",
      "Extracting_1226866_Inns2_Page4 content\n",
      "Extracting_1226866_Inns2_Page5 content\n",
      " \n",
      "Extracting_1226863_Inns1_Page1 content\n",
      "Extracting_1226863_Inns1_Page2 content\n",
      "Extracting_1226863_Inns1_Page3 content\n",
      "Extracting_1226863_Inns1_Page4 content\n",
      "Extracting_1226863_Inns1_Page5 content\n",
      "Extracting_1226863_Inns2_Page1 content\n",
      "Extracting_1226863_Inns2_Page2 content\n",
      "Extracting_1226863_Inns2_Page3 content\n",
      "Extracting_1226863_Inns2_Page4 content\n",
      "Extracting_1226863_Inns2_Page5 content\n",
      " \n",
      "Extracting_1226867_Inns1_Page1 content\n",
      "Extracting_1226867_Inns1_Page2 content\n",
      "Extracting_1226867_Inns1_Page3 content\n",
      "Extracting_1226867_Inns1_Page4 content\n",
      "Extracting_1226867_Inns1_Page5 content\n",
      "Extracting_1226867_Inns2_Page1 content\n",
      " \n",
      "Extracting_1226830_Inns1_Page1 content\n",
      "Extracting_1226830_Inns1_Page2 content\n",
      "Extracting_1226830_Inns1_Page3 content\n",
      "Extracting_1226830_Inns1_Page4 content\n",
      "Extracting_1226830_Inns1_Page5 content\n",
      "Extracting_1226830_Inns2_Page1 content\n",
      "Extracting_1226830_Inns2_Page2 content\n",
      "Extracting_1226830_Inns2_Page3 content\n",
      "Extracting_1226830_Inns2_Page4 content\n",
      "Extracting_1226830_Inns2_Page5 content\n",
      " \n",
      "Scraping process over\n"
     ]
    }
   ],
   "source": [
    "#Declaring all lists and dataframes\n",
    "match_list=[]\n",
    "inns_list=[]\n",
    "ball_list=[]\n",
    "over_list=[]\n",
    "runs_list=[]\n",
    "comm_short_list=[]\n",
    "comm_long_list=[]\n",
    "bat_team_list=[]\n",
    "bowl_team_list=[]\n",
    "striker_bat_id_list=[]\n",
    "nonstriker_bat_id_list=[]\n",
    "striker_bat_name_list=[]\n",
    "nonstriker_bat_name_list=[]\n",
    "main_bow_id_list=[]\n",
    "other_bow_id_list=[]\n",
    "main_bow_name_list=[]\n",
    "other_bow_name_list=[]\n",
    "isBoundary_list=[]\n",
    "wide_runs_list=[]\n",
    "#legbye_runs_list=[]\n",
    "bye_legbye_runs_list=[]\n",
    "nb_runs_list=[]\n",
    "batsman_runs_list=[]\n",
    "extras_runs_list=[]\n",
    "is_wkt_list=[]\n",
    "is_bow_wkt_list=[]\n",
    "wkt_data_list=[]\n",
    "curr_bat_list=[]\n",
    "curr_bow_list=[]\n",
    "curr_inn_list=[]\n",
    "match_over_list=[]\n",
    "ball_data_old=pd.read_csv('Output folder\\BBB_data.csv')\n",
    "match_data=pd.read_csv('Output folder\\Matches_data.csv',index_col='Overall Match Id')\n",
    "\n",
    "for mid in matchid_list:\n",
    "    #url_match='https://www.espncricinfo.com/series/8048/commentary/{}/trinbago-knight-riders-vs-st-kitts-and-nevis-patriots-1st-match-caribbean-premier-league-2019'.format(mid)\n",
    "    #driver = webdriver.Chrome(\"D:/Downloads/chromedriver_win32/chromedriver.exe\")\n",
    "    #driver.get(url_match)\n",
    "    #content = driver.page_source\n",
    "    #soup = BeautifulSoup(content)\n",
    "    #team_list=[]\n",
    "    #for teams in soup.findAll('div',attrs={'class':'teams'}):\n",
    "     #   for team in teams.findAll('div',attrs={'class':'team'}):\n",
    "        #team_list.append(team.find('span').attrs['title'])\n",
    "            #team_list.append(team.findAll('p',attrs={'class':'name'}))\n",
    "      #      print(team.find('p',attrs={'class':'name'}).text)\n",
    "    \n",
    "    #driver.quit()    \n",
    "    for inns in np.arange(1,3):\n",
    "        url='https://hsapi.espncricinfo.com/v1/pages/match/comments?lang=en&leagueId=8048&eventId={match}&liveTest=false&period={inns}&page=1'.format(match=mid,inns=inns)\n",
    "        driver = webdriver.Chrome(\"D:/Downloads/chromedriver_win32/chromedriver.exe\")\n",
    "        driver.get(url)\n",
    "        content = driver.page_source\n",
    "        soup = BeautifulSoup(content)\n",
    "        total_pages=json.loads(soup.text)['pagination']['pageCount']\n",
    "        driver.quit()\n",
    "        \n",
    "        for page in np.arange(total_pages):\n",
    "            #Code to retrieve json data for the page\n",
    "            url_page='https://hsapi.espncricinfo.com/v1/pages/match/comments?lang=en&leagueId=8048&eventId={match}&liveTest=false&period={inns}&page={page}'.format(match=mid,inns=inns,page=page+1)\n",
    "            driver = webdriver.Chrome(\"D:/Downloads/chromedriver_win32/chromedriver.exe\")\n",
    "            driver.get(url_page)\n",
    "            content = driver.page_source\n",
    "            soup = BeautifulSoup(content)\n",
    "            soup_data=json.loads(soup.text)\n",
    "            print('Extracting_{match}_Inns{inns}_Page{page} content'.format(match=mid,inns=inns,page=page+1))\n",
    "            #with open('Downloaded webpages\\CPL_2019_{match}_Inns{inns}_Page{page}.html'.format(match=mid,inns=inns,page=page+1), 'w') as f:\n",
    "            #    f.write(content)\n",
    "            #driver.quit()\n",
    "            #print('Downloaded CPL_2019_{match}_Inns{inns}_Page{page} webpage'.format(match=mid,inns=inns,page=page+1))\n",
    "            \n",
    "            #Code to load page json data into dataframe\n",
    "            #with open('Downloaded webpages\\CPL_2019_{match}_Inns{inns}_Page{page}.html'.format(match=mid,inns=inns,page=page+1)) as fp:\n",
    "            #    soup_data = json.loads(BeautifulSoup(fp, \"html5lib\").text)\n",
    "            for ball_ind in np.arange(len(soup_data['comments'])):\n",
    "                ball_data=soup_data['comments'][ball_ind]\n",
    "                if ball_data['ball']==0:\n",
    "                    continue\n",
    "                match_list.append(mid)\n",
    "                inns_list.append(inns)\n",
    "                if inns==1:\n",
    "                    bat_team_list.append(match_data.loc[int(mid)]['Home team name'])\n",
    "                    bowl_team_list.append(match_data.loc[int(mid)]['Away team name'])\n",
    "                else:\n",
    "                    bat_team_list.append(match_data.loc[int(mid)]['Away team name'])\n",
    "                    bowl_team_list.append(match_data.loc[int(mid)]['Home team name'])        \n",
    "                ball_list.append(ball_data['ball'])\n",
    "                over_list.append(ball_data['over']+1)\n",
    "                runs_list.append(ball_data['runs'])\n",
    "                if 'shortText' in ball_data:\n",
    "                    comm_short_list.append(ball_data['shortText'])\n",
    "                else:\n",
    "                    comm_short_list.append(np.nan)\n",
    "                comm_long_list.append(ball_data['text'])\n",
    "                striker_bat_id_list.append(ball_data['currentBatsmen'][0]['id'])\n",
    "                nonstriker_bat_id_list.append(ball_data['currentBatsmen'][1]['id'])\n",
    "                striker_bat_name_list.append(ball_data['currentBatsmen'][0]['name'])\n",
    "                nonstriker_bat_name_list.append(ball_data['currentBatsmen'][1]['name'])\n",
    "                main_bow_id_list.append(ball_data['currentBowlers'][0]['id'])\n",
    "                main_bow_name_list.append(ball_data['currentBowlers'][0]['name'])\n",
    "                extras_runs_list.append(0)\n",
    "\n",
    "                if 'id' in ball_data['currentBowlers'][1]:\n",
    "                    other_bow_id_list.append(ball_data['currentBowlers'][1]['id'])\n",
    "                else:\n",
    "                    other_bow_id_list.append(np.nan)\n",
    "\n",
    "                if 'name' in ball_data['currentBowlers'][1]:\n",
    "                    other_bow_name_list.append(ball_data['currentBowlers'][1]['name'])                    \n",
    "                else:\n",
    "                    other_bow_name_list.append(np.nan)\n",
    "\n",
    "                if str(ball_data['isBoundary'])=='True':\n",
    "                    isBoundary_list.append(1)\n",
    "                else:\n",
    "                    isBoundary_list.append(0)\n",
    "\n",
    "                if str(ball_data['isWide'])=='True':\n",
    "                    wide_runs_list.append(ball_data['runs'])\n",
    "                    nb_runs_list.append(0)\n",
    "                    bye_legbye_runs_list.append(0)\n",
    "                    batsman_runs_list.append(0)\n",
    "                elif ((str(ball_data['isNoball'])=='True')):\n",
    "                    wide_runs_list.append(0)\n",
    "                    #bye_legbye_runs_list.append(0)\n",
    "                    #print(inns,ball_data['over']+1,ball_data['ball'])\n",
    "                    if (re.search('[(]no ball[)]', ball_data['shortText'])):\n",
    "                        if ('bye' in ball_data['shortText'].split(', ')[1]):\n",
    "                            #print('Scenario 1')\n",
    "                            nb_runs_list.append(1)\n",
    "                            bye_legbye_runs_list.append(ball_data['runs'] - 1)\n",
    "                            batsman_runs_list.append(0)\n",
    "                        else:\n",
    "                            #print('Scenario 2')\n",
    "                            nb_runs_list.append(1)\n",
    "                            bye_legbye_runs_list.append(0)\n",
    "                            batsman_runs_list.append(ball_data['runs'] - 1)                            \n",
    "                    else:    \n",
    "                        nb_runs_list.append(ball_data['runs'])\n",
    "                        batsman_runs_list.append(0)\n",
    "                        bye_legbye_runs_list.append(0)\n",
    "                elif ('bye' in ball_data['shortText'].split(', ')[1]):\n",
    "                    bye_legbye_runs_list.append(ball_data['runs'])\n",
    "                    wide_runs_list.append(0)\n",
    "                    nb_runs_list.append(0)                    \n",
    "                    batsman_runs_list.append(0)\n",
    "                else:\n",
    "                    wide_runs_list.append(0)\n",
    "                    nb_runs_list.append(0)\n",
    "                    batsman_runs_list.append(ball_data['runs']) \n",
    "                    bye_legbye_runs_list.append(0)\n",
    "\n",
    "                if 'matchWicket' in ball_data:\n",
    "                    is_wkt_list.append(1)\n",
    "                    wkt_data_list.append(ball_data['matchWicket'])\n",
    "                    if re.search('(run out|obstructing the field)',ball_data['matchWicket']['text']):\n",
    "                        is_bow_wkt_list.append(0)\n",
    "                    else:\n",
    "                        is_bow_wkt_list.append(1)\n",
    "                else:\n",
    "                    is_wkt_list.append(0)\n",
    "                    wkt_data_list.append(0)\n",
    "                    is_bow_wkt_list.append(0)\n",
    "\n",
    "                if 'matchOver' in ball_data:\n",
    "                    match_over_list.append(ball_data['matchOver'])\n",
    "                else:\n",
    "                    match_over_list.append(0)\n",
    "\n",
    "                curr_bat_list.append(ball_data['currentBatsmen'])\n",
    "                curr_bow_list.append(ball_data['currentBowlers'])\n",
    "                curr_inn_list.append(ball_data['currentInning'])\n",
    "            driver.quit()        \n",
    "    \n",
    "    print(' ')\n",
    "    \n",
    "ball_by_ball_df=pd.DataFrame(list(zip(match_list,inns_list,over_list,ball_list,bat_team_list,bowl_team_list,striker_bat_id_list,striker_bat_name_list,nonstriker_bat_id_list,nonstriker_bat_name_list,main_bow_id_list,main_bow_name_list,other_bow_id_list,other_bow_name_list,isBoundary_list,wide_runs_list,nb_runs_list,bye_legbye_runs_list,extras_runs_list,batsman_runs_list,runs_list,is_wkt_list,is_bow_wkt_list,wkt_data_list,match_over_list,curr_bat_list,curr_bow_list,curr_inn_list,comm_short_list,comm_long_list)),\n",
    "                             columns=['Match_id','Inns','Over','Ball','Batting team','Bowling team','Strike batsman id','Strike batsman name','Non-strike batsman id','Non-strike batsman name','Main bowler id','Main bowler name','Other end bowler id','Other end bowler name','Is Boundary','Wide runs','No ball runs','Bye and leg bye runs','Extras runs','Batsman runs','Total Runs','Is wicket','Is Bowler wicket','Wicket data','Over data','Batsmen data','Bowlers data','Innings data until then','Short comm','Long Comm'])\n",
    "ball_by_ball_df['Extras runs']=ball_by_ball_df['Wide runs']+ball_by_ball_df['No ball runs']+ball_by_ball_df['Bye and leg bye runs']\n",
    "ball_by_ball_df=ball_data_old.append(ball_by_ball_df,ignore_index=True)\n",
    "ball_by_ball_df=ball_by_ball_df.sort_values(['Match_id','Inns','Over','Ball'])\n",
    "ball_by_ball_df.to_csv('Output folder\\BBB_data.csv',index=False) \n",
    "\n",
    "print('Scraping process over')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Players data (incremental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of player ids  [677081, 1182529]\n",
      "Extracting player 677081 data\n",
      "Extracting player 1182529 data\n",
      "Scraping process over\n"
     ]
    }
   ],
   "source": [
    "players_id=[]\n",
    "players_df_old=pd.read_csv('Output folder\\Players_data.csv',index_col='Player Id')\n",
    "players_df=pd.DataFrame(columns=['Player Id','Full Name','Playing role','Batting style','Bowling style'])\n",
    "\n",
    "bbb_data=pd.read_csv('Output folder\\BBB_data.csv')\n",
    "#bbb_data.dropna(subset=['Other end bowler id'], inplace=True)\n",
    "#bbb_data['Other end bowler id']=bbb_data['Other end bowler id'].astype(int)\n",
    "\n",
    "players_id.append(list(set(bbb_data['Strike batsman id'])))\n",
    "players_id.append(list(set(bbb_data['Non-strike batsman id'])))\n",
    "players_id.append(list(set(bbb_data['Main bowler id'])))\n",
    "players_id.append(list(set(bbb_data['Other end bowler id'])))\n",
    "\n",
    "players_list = [item for sublist in players_id for item in sublist]\n",
    "players_list = [x for x in players_list if str(x) != 'nan']\n",
    "players_list = [x for x in players_list if str(x) != 'undefined']\n",
    "players_list=[int(p) for p in players_list]\n",
    "players_list=list(set(players_list))\n",
    "\n",
    "players_df['Player Id']=[p for p in players_list if p not in players_df_old.index.values.tolist()]\n",
    "players_df.set_index('Player Id',inplace=True)\n",
    "print('List of player ids ',players_df.index.values.tolist())\n",
    "\n",
    "for pid in players_df.index.values.tolist():\n",
    "    url_page='https://www.espncricinfo.com/india/content/player/{}.html'.format(pid)\n",
    "    driver = webdriver.Chrome(\"D:/Downloads/chromedriver_win32/chromedriver.exe\")\n",
    "    driver.get(url_page)\n",
    "    content = driver.page_source\n",
    "    soup = BeautifulSoup(content)\n",
    "    \n",
    "    print('Extracting player {} data'.format(pid))\n",
    "    \n",
    "    for tag in soup.findAll('p',attrs={'class':'ciPlayerinformationtxt'}):\n",
    "        for subtag in tag.findAll('b'):\n",
    "            if subtag.text == 'Full name':\n",
    "                players_df.loc[pid]['Full Name']=tag.findAll('span')[0].text\n",
    "            if subtag.text == 'Playing role':\n",
    "                players_df.loc[pid]['Playing role']=tag.findAll('span')[0].text\n",
    "            if subtag.text == 'Batting style':\n",
    "                players_df.loc[pid]['Batting style']=tag.findAll('span')[0].text\n",
    "            if subtag.text == 'Bowling style':\n",
    "                players_df.loc[pid]['Bowling style']=tag.findAll('span')[0].text\n",
    "    driver.quit()        \n",
    "\n",
    "print('Scraping process over')  \n",
    "players_df=players_df_old.append(players_df)\n",
    "players_df=players_df.sort_index()\n",
    "players_df.to_csv('Output folder\\Players_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ball_by_ball_df=pd.read_csv('Output folder\\BBB_data.csv')\n",
    "#ball_by_ball_df=ball_by_ball_df.sort_values(['Match_id','Inns','Over','Ball'])\n",
    "#ball_by_ball_df.to_csv('Output folder\\BBB_data.csv',index=False) \n",
    "len(set(ball_by_ball_df['Match_id']))\n",
    "\n",
    "#len(matches_df['Overall Match Id'])\n",
    "\n",
    "#ball_by_ball_df=ball_by_ball_df.sort_values(['Match id','Inns','Over','Ball'])\n",
    "#ball_by_ball_df.to_csv('Output folder\\BBB_data.csv',index=False) \n",
    "\n",
    "#ball_by_ball_df=ball_by_ball_df.sort_values(['Match id','Inns','Over','Ball'])\n",
    "#ball_by_ball_df.to_csv('Output folder\\Test.csv',index=False)\n",
    "\n",
    "#team_list=[]\n",
    "#match_data=pd.read_csv('Output folder\\Matches_data.csv',index_col='Overall Match Id')\n",
    "#team_list.append(match_data.loc[int(mid)][['Home team name','Away team name']])\n",
    "#team_list.shape\n",
    "\n",
    "#players_df=pd.read_csv('Output folder\\Players_data.csv',index_col='Player Id')\n",
    "#players_df=players_df.sort_values('Player Id')\n",
    "#players_df=players_df[~players_df.index.duplicated(keep='first')]\n",
    "#players_df.to_csv('Output folder\\Players_data.csv')\n",
    "\n",
    "#ball_by_ball_df.to_csv('Output folder\\BBB_data.csv',index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Power surge comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Downloads\\Anaconda\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (8,30) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "ball_by_ball_df=pd.read_csv('Output folder\\BBB_data.csv')\n",
    "#ball_by_ball_df=ball_by_ball_df.rename(columns={'Match id':'Match_id'})\n",
    "#ball_by_ball_df['Comments']=np.where((ball_by_ball_df['Match_id'].astype(int)==1226830) & (ball_by_ball_df['Inns']==1) & \n",
    "#                                     (ball_by_ball_df['Over'].isin([17,18])),'Power Surge',ball_by_ball_df['Comments'])\n",
    "#ball_by_ball_df['Comments']=np.where((ball_by_ball_df['Match_id'].astype(int)==1226830) & (ball_by_ball_df['Inns']==2) & \n",
    "#                                     (ball_by_ball_df['Over'].isin([14,15])),'Power Surge',ball_by_ball_df['Comments'])\n",
    "#print(ball_by_ball_df[ball_by_ball_df['Comments']=='Power Surge'])\n",
    "\n",
    "ball_by_ball_df['Is_legal_ball_team']=np.where((ball_by_ball_df['Wide runs'] > 0) | (ball_by_ball_df['No ball runs'] > 0), 0, 1)\n",
    "ball_by_ball_df['Is_legal_ball_batsman']=np.where(ball_by_ball_df['Wide runs'] > 0, 0, 1)\n",
    "\n",
    "ball_by_ball_df.to_csv('Output folder\\BBB_data.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
